# Reinforcement Learning Models

Models for learning through interaction with an environment.

## Value-Based Methods

### Tabular Methods
1. **QLearning.tsx** - Classic Q-learning
2. **SARSA.tsx** - State-action-reward-state-action
3. **ExpectedSARSA.tsx** - Expected SARSA

### Deep RL
4. **DQN.tsx** - Deep Q-Network
5. **DoubleDQN.tsx** - Double DQN
6. **DuelingDQN.tsx** - Dueling architecture
7. **RainbowDQN.tsx** - Combined improvements

## Policy-Based Methods
8. **REINFORCE.tsx** - Monte Carlo policy gradient
9. **VPG.tsx** - Vanilla policy gradient

## Actor-Critic Methods
10. **A2C.tsx** - Advantage Actor-Critic
11. **A3C.tsx** - Asynchronous A3C
12. **DDPG.tsx** - Deep deterministic policy gradient
13. **TD3.tsx** - Twin delayed DDPG
14. **SAC.tsx** - Soft actor-critic

## Policy Optimization
15. **PPO.tsx** - Proximal policy optimization
16. **TRPO.tsx** - Trust region policy optimization

## Model-Based RL
17. **Dyna-Q.tsx** - Model-based planning
18. **AlphaZero.tsx** - Self-play learning

## Multi-Agent RL
19. **MADDPG.tsx** - Multi-agent DDPG
20. **QMIX.tsx** - Value decomposition

## Use Cases:
- Game playing (Chess, Go, Atari)
- Robotics control
- Autonomous vehicles
- Resource allocation
- Trading strategies
- Recommendation systems

## Note:
RL models require:
- Environment definition
- Reward function
- State/action spaces
- Extensive training episodes

